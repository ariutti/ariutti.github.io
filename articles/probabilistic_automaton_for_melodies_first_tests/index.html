<html>
<head>
  <meta charset="UTF-8">
  <!-- <link rel="alternate" type="application/rss+xml"  title="put your RSS title here" href="/rss.xml" /> -->
  <style type="text/css">

    @font-face {
      font-family: 'fabfont';
/*      font-display: optional;*/
      src: url('/font/DejaVuSansMono.woff2');
    }

    * {
       font-size: 16px;
    }

    html {
      font-family: fabfont;
      max-width: 900px;  /* For Desktop PC (see @media for Tablets/Phones) */
      padding-left: 2%;
      padding-right: 3%;
      margin: 0 auto;
      background: #F5F5F0;
  	}

  	a {
      color: black;
      font-weight: bold;
    }

    img {
      border: none;
    }

    p {
      margin-top: 0px;
      text-align: justify;
    }
    sup {
      vertical-align: 0.3em;
      font-size: 0.65em;
    }

    pre {
      font-family: fabfont;
      background-color: white;
      border: 1px solid Black;
      padding-left: 2%;
      padding-top: 1ch;
      padding-bottom: 1ch;
      /* Only take care of X overflow since this is the only part that can be too wide.
         The Y axis will never overflow.
      */
      overflow: hidden;
    }

    div.heading {
      font-weight: bold;
      text-transform: uppercase;
      margin-top: 4ch;
    }

    /** {
      font-size: 16px;
    }*/
    @media (max-width: 500px) { /* For small screen decices */
      * {
        font-size: 12px;
      }
    }
    .title {
      text-decoration: none;
    }

    img.pixel, canvas.pixel {
      image-rendering: pixelated;
      image-rendering: -moz-crisp-edges;
      image-rendering: crisp-edges;
    }

    blockquote {
      background-color: #f3f3f3;
      border: dashed 1px grey;
      width: 97.5%;
      font-style: italic;
      text-align: justify;

      padding: 1ch;
      padding-top: 2ch;
      padding-bottom: 2ch;

      margin : 0ch;
      margin-bottom: 2ch;
      margin-top: 0ch;
    }

    blockquote div {
      text-transform: none;
      text-align: right;
      width: 100%;
    }

  .note {
    position: relative;
    background-color: #ffd700;
    padding: 1em;
    margin: 1em 0 2em;
    border-radius: 5px;
  }

  code {
    /*font-size: 110%;*/
    font-weight: bold;
    background-color: #e1e1e1;
    border-radius: 0.5ch;
    padding-left: 0.3ch;
    padding-right: 0.3ch;
  }


  /* GENERIC TABLE */
  table {
    border-collapse: collapse;
  }

  table td, th {
    border:1px solid #ccc;
  }

  /* REFERENCES TABLE - which stands inside the footer*/
  table.references td {
    border:none;
  }

  table.references th {
    border:none;
  }


  /* TABELLA WALK MATRIX */
  table.walk-matrix {
      font-size: 0.8em;
      width: 70%;
      margin:auto;
      border-collapse: collapse;
  }

  /*
  table.walk-matrix th {
      background-color: #ccc;
      text-align: center;
      padding: 5px;
      border:1px solid #fff;
  }
  */

  table.walk-matrix td {
      width: 8%;
      text-align: center;
      padding: 5px;
      border:1px solid #ccc;
  }

  table.walk-matrix td.gray1{
      background-color: #ddd;
  }

  table.walk-matrix td.gray2{
      background-color: #eee;
  }


  </style>
  <title>Probabilistic automaton for creating melodies (first tests)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=12.0, minimum-scale=1.0, user-scalable=yes">
</head>
  <body><br><center>
    <div style="display: inline-block; vertical-align:middle;">
<a href="/" class="title"><b>NICOLA ARIUTTI'S WEBSITE</b><br>
</a><hr/><div style="text-align: justify;display: inline-block; width: 100%;">
<!--<a class="title" href="/about">ABOUT</a> &nbsp;<a class="title" href="/contact/index.html">EMAIL</a> &nbsp;<a class="title" href="../rss.xml">RSS</a> &nbsp;<a class="title" href="put here your paypal link">DONATE</a></div></div>-->
<a class="title" href="/about">ABOUT</a> &nbsp;<a class="title" href="/contact/index.html">CONTACT</a> &nbsp;</div></div>

</center><br><br>
<div style="margin-bottom: 2ch;text-transform: none;">
October 17, 2024</div>
<div class='heading' id='probabilistic-automaton-for-creating-melodies-(first-tests)'>Probabilistic automaton for creating melodies (first tests)</div><hr/>
<p>Making music by means of designing systems that make music stands at the base of the <i>generative music</i><a name="back_1" style="text-decoration: none;" href="#footnote_1"><sup>[1]</sup></a> concept.</p>
<p>This article covers my early experiments in building a probabilistic machine for the automatic generation of melodies.</p>

<div class='heading' id='hollos-brothers'>Hollos brothers</div><hr/>
<p>Some time ago, by chance, I came across the small publishing house <a href="https://abrazol.com/">Abrazol Publishing</a>, which seems to exclusively publish books written by the brothers <a href="https://www.exstrom.com/stefan/stefan.html">Stefan</a> and <a href="https://www.exstrom.com/richard/richard.html">J. Richard</a> Hollos (maybe because they own it?).</p>

<img loading="lazy" src="images/cover_creating_rhythms.png" width="300" height="480" style="width: 20%; height: auto; float:left; margin-bottom: 2ch; margin-right: 2ch; margin-left:1ch;"/><img loading="lazy" src="images/cover_creating_melodies.png" width="300" height="480" style="width: 20%; height: auto; float:left; margin-bottom: 2ch; margin-right: 2ch; margin-left:1ch;"/>
<p>The two brothers, both graduates in Electrical Engineering and Physics, are passionate about mathematics, statistics, probability, electronics, and art, and together they write about these subjects in their books.</p>

<p>Their books are fascinating and intriguing, starting with their cover design. Written in a simple and accessible language, they are full of interesting insights and reflect the authors' passion for these fields.</p>

<p>I read two of their books, the ones that seemed to best combine the engineering, logical-mathematical aspect with the artistic expression of music.</p>
<p>These are "<a href="https://abrazol.com/books/rhythm1/">Creating Rhythms</a>" and "<a href="https://abrazol.com/books/melody1/">Creating Melodies</a>", both highly recommended.</p>

<div class='heading' id='olson'>Olson</div><hr/>
<p>In particular, there is a chapter in the book "<i>Creating Melodies</i>" where the Hollos brothers describe a probabilistic automaton capable of generating convincing melodies based on prepared material on which the machine is trained.</p>

<img loading="lazy" src="images/cover_music-physics-and-engineering.jpg" width="1200" height="1887" style="width: 20%; height: auto; float:right; margin-bottom: 2ch; margin-right: 1ch; margin-left:2ch;"/>
<p>The example that Stefan and Richard describe is based on the work of another author, Harry F. Olson, who in 1952 published a book titled "<i>Musical Engineering</i>" (known from 1962 onwards as "<i>Music, Physics and Engineering</i>").</p>

<p>In this book, Olson develops this automaton and applies it to various levels of increasing complexity (<i>orders</i>) to produce a melody that progressively stylistically resembles the input sound material (<i>dataset</i>) provided.</p>

<p>All of this piqued my curiosity, and I decided to try implementing this automaton myself using Python.</p>

<div style="clear:both;"></div>


<div class='heading' id='what-a-melody-is'>What a melody is</div><hr/>
<p>First of all, what is a melody<a name="back_2" style="text-decoration: none;" href="#footnote_2"><sup>[2]</sup></a>?</p>

<p>It is a musical phrase, a "<i>gesture</i>" composed of a finite sequence of sounds at different pitches (<i>notes</i>) and silences (<i>rests</i>). Each note follows and precedes other notes, thus forming a distinctive and recognizable "<i>contour</i>" from a horizontal perspective.</p>

<p>Each note also has a precise duration, and together these durations define the rhythm of the melody. Furthermore some notes fall on the strong beats of the measure, while others occur on the weaker beats, suggesting a more or less pronounced sense of tonality within which the melody exists and moves.</p>

<p>To add a few more elements, it should be noted that, much like spoken language, every part of a musical phrase has its own dynamics, the volume and expression of each note evolve organically with the development of the phrase.</p>

<p>In short, there are many elements to consider when procedurally creating a melody, but by starting as simply as possible, we can overlook everything except the notes with their pitches and the rests.</p>

<div class='heading' id='dataset-preparation'>Dataset preparation</div><hr/>
<p>To test the effectiveness of the code, I decided to use a simple and well-known melody: "<i>Old McDonald</i>" (is that the actual name?):</p>

<div style="text-align: center;">
<img loading="lazy" src="images/old_mc_donald_score.png" width="763" height="122" style="width: 80%; height: auto; margin-top: 2ch; margin-bottom: 2ch;"/></div>

<div style="text-align: center;">
<audio controls="" style="width:80%; margin-bottom: 2ch;"> <source src="sounds/old_mc_donald.ogg" type="audio/ogg"> </audio>
</div>

<p>I wrote the melody using Reaper, my favorite DAW, making sure to quantize each note properly and then exporting it in MIDI format, intending to parse it later in Python using the <a href="https://www.music21.org/music21docs/">music21</a> library.</p>

<p>If our algorithm is well designed, I expect the output melody to show more or less significant similarities to the original.</p>

<div class='heading' id='first-order-automaton'>First order automaton</div><hr/>
<p>A first analysis we can perform on the given melody is to count how often each note appears. Hereâ€™s a heatmap showing the frequency of the notes within our starting melody:</p>

<div style="text-align: center;">
<img loading="lazy" src="images/graphs_no_duration/old_mc_donald_1_order_heatmap.png" width="814" height="179" style="width: 80%; height: auto; margin-top: 2ch; margin-bottom: 2ch;"/></div>

<p>Starting from this initial statistical analysis, we can create the simplest automaton: a <i>first-order</i> automaton. It generates new notes based on the frequency with which they appear in the original melody.</p>

<p>In other words, the first-order automaton randomly selects notes from those present in the original melody. Notes that appeared more frequently in the original melody will have a higher probability of being chosen.</p>

<p>Hereâ€™s what a minute of audio output from a first-order automaton trained on our melody sounds like:</p>

<div style="text-align: center;">
<audio controls="" style="width:80%; margin-bottom: 2ch;"> <source src="sounds/1st_no_duration.ogg" type="audio/ogg"> </audio>
</div>

<p>So far, so good. The algorithm works, but with such a simple automaton, the result still sounds musically quite rudimentary. Letâ€™s try to make things a bit more complex and ask ourselves a few more questions.</p>

<p>After all, a melody is not just a random sequence of notes. Each note follows another based on the composerâ€™s artistic intention. The composer is like an architect, arranging the notes according to a certain design to express or convey something. How can we account for that?</p>

<div class='heading' id='second-order-automaton'>Second order automaton</div><hr/>
<p>For example, we can build a new automaton capable of selecting the next note based on the previously selected one. This is the <i>second-order</i> automaton, which analyzes the dataset by extracting information about two-note sequences.</p>

<p>Here is a heatmap representing a second-order statistic of our starting melody:</p>

<div style="text-align: center;">
<img loading="lazy" src="images/graphs_no_duration/old_mc_donald_2_order_heatmap.png" width="695" height="721" style="width: 60%; height: auto; margin-top: 1ch; margin-bottom: 2ch;"/></div>

<p>For fun, we could also represent these relationships with a connected graph, where each note is represented by a <i>node</i>, and each connection (<i>edge</i>) represents the relationship between two notes. Each edge is drawn with varying thickness depending on the probability of transition from one note to another.</p>

<p>This type of representation can help us better visualize the different decision pathways the algorithm may take when generating a new note.</p>

<div style="text-align: center;">
<img loading="lazy" src="images/graphs_no_duration/old_mc_donald_dotgraph.png" width="305" height="708" style="width: 40%; height: auto; margin-top: 1ch; margin-bottom: 2ch;"/></div>

<p>But the real question is: how does a second-order automaton sound? Can we hear differences compared to the previous automaton? How significant are these changes?</p>

<div style="text-align: center;">
<audio controls="" style="width:80%; margin-bottom: 2ch;"> <source src="sounds/2nd_no_duration.ogg" type="audio/ogg"> </audio>
</div>

<p>You may notice that as the automaton's order increases, the notes follow one another in a different way, and the profile of this new output melody more closely resembles the original musical material.</p>

<div class='heading' id='higher-order-automatons'>Higher order automatons</div><hr/>
<p>We could take this reasoning even further by analyzing sequences of 3 notes, thus creating a third-order automaton. This automaton can generate a new note based on the two notes previously played.</p>

<div style="text-align: center;">
<img loading="lazy" src="images/graphs_no_duration/old_mc_donald_3_order_heatmap.png" width="392" height="721" style="width: 40%; height: auto; margin-top: 1ch; margin-bottom: 2ch;"/></div>

<div style="text-align: center;">
<audio controls="" style="width:80%; margin-bottom: 2ch;"> <source src="sounds/3rd_no_duration.ogg" type="audio/ogg"> </audio>
</div>

<p>Similarly for the fourth order:</p>

<div style="text-align: center;">
<img loading="lazy" src="images/graphs_no_duration/old_mc_donald_4_order_heatmap.png" width="380" height="721" style="width: 40%; height: auto; margin-top: 1ch; margin-bottom: 2ch;"/></div>

<div style="text-align: center;">
<audio controls="" style="width:80%; margin-bottom: 2ch;"> <source src="sounds/4th_no_duration.ogg" type="audio/ogg"> </audio>
</div>

<p>and so on...</p>

<div class='heading' id='first-considerations'>First considerations</div><hr/>
<p>These initial results are interesting in my opinion because they show how, based on statistics and probability, machines can autonomously generate new melodies that still resemble the material provided as the initial dataset.</p>
<p>I can imagine using them in a multimedia installation context where itâ€™s necessary to produce new, always different, but consistent music within a given style. Music that can be continuously and automatically generated.</p>

<p>From these early experiments, Iâ€™ve noticed that dataset preparation is a crucial phase. For the machine to be reliable and produce results that are both consistent and varied, the dataset must be large and comprehensive. It should contain as many possible note combinations as well as rhythmic and melodic patterns that repeat themselves, allowing the automaton to choose among different possible paths.</p>

<p>I imagine one could, for example, record a long performance and convert it into a MIDI file. By using this MIDI file as the dataset, the automaton would, in a sense, become an alter ego, able to propose new melodies that reflect our own taste and playing style :)</p>

<p>As we mentioned before, we have not yet considered other fundamental aspects of melody generation, such as rhythm or dynamics. What results could we obtain if we did?</p>
<p>What would happen if, for example, our automaton also considered the duration of each note in its statistical analysis of the input score?</p>

<div class='heading' id='adding-time-|-rhythm'>Adding time | rhythm</div><hr/>
<p>If we change the code of our algorithm and add a feature to analyze the duration of each note in addition to its pitch, the first-order heatmap becomes more detailed than the one we encountered earlier. In the melody, notes that share the same pitch now become distinct entities because they have different durations.</p>

<div style="text-align: center;">
<img loading="lazy" src="images/graphs_w_duration/old_mc_donald_1_order_heatmap.png" width="815" height="203" style="width: 80%; height: auto; margin-top: 1ch; margin-bottom: 2ch;"/></div>

<p>Even though this is a first-order automaton, upon first listening, it becomes clear that the output better reflects the melodic idea of the dataset, respecting not only the pitches but also the durations.</p>

<div style="text-align: center;">
<audio controls="" style="width:80%; margin-bottom: 2ch;"> <source src="sounds/1st_w_duration.ogg" type="audio/ogg"> </audio>
</div>

<p>As we increase the automatonâ€™s order, the corresponding sound result becomes increasingly similar to the original material.<p>

<div style="text-align: center;">
<img loading="lazy" src="images/graphs_w_duration/old_mc_donald_2_order_heatmap.png" width="762" height="763" style="width: 80%; height: auto; margin-top: 1ch; margin-bottom: 2ch;"/></div>

<div style="text-align: center;">
<audio controls="" style="width:80%; margin-bottom: 2ch;"> <source src="sounds/2nd_w_duration.ogg" type="audio/ogg"> </audio>
</div>

<div style="text-align: center;">
<img loading="lazy" src="images/graphs_w_duration/old_mc_donald_3_order_heatmap.png" width="599" height="763" style="width: 60%; height: auto; margin-top: 1ch; margin-bottom: 2ch;"/></div>

<div style="text-align: center;">
<audio controls="" style="width:80%; margin-bottom: 2ch;"> <source src="sounds/3rd_w_duration.ogg" type="audio/ogg"> </audio>
</div>

<div style="text-align: center;">
<img loading="lazy" src="images/graphs_w_duration/old_mc_donald_4_order_heatmap.png" width="612" height="763" style="width: 60%; height: auto; margin-top: 1ch; margin-bottom: 2ch;"/></div>

<div style="text-align: center;">
<audio controls="" style="width:80%; margin-bottom: 2ch;"> <source src="sounds/4th_w_duration.ogg" type="audio/ogg"> </audio>
</div>

<div class='heading' id='considerations,-pt2'>Considerations, pt2</div><hr/>
<p>You can hear that, as we increase the automatonâ€™s order, the sound result changes. However, the higher the order, the more the variety of possible outputs decreases, and randomness begins to fade away: the resulting melody, especially at higher orders, becomes almost identical to the one provided as input.</p>

<p>While this demonstrates the effectiveness of the algorithm, it also raises questions about this machine's true capability to be versatile enough to generate "new" music that captivates the listener. The risk of generating excessive repetitiveness and monotony is evident.</p>

<p>I also believe that the main reason why higher-order automatons seem less effective is essentially due to the dataset size.</p>

<p>Looking closely, the melody I chose for these early tests is very simple and extremely short.</p>

<p>I can't wait to continue these experiments by subjecting the algorithm to a larger and more varied dataset.</p>

<div class='heading' id='the-code'>The code</div><hr/>
<p>You can find the code I wrote on <a href="https://github.com/ariutti/probabilistic_automaton_for_melody_generation">this GitHub repository</a>.</p>

<p>The code is essentially capable of parsing a MIDI file and performing a series of statistical analyses (via the music21 module) to build as many state machines as desired.</p>

<p>The descriptions of the state machines generated in this way are saved in <code>yaml</code> format so that they can easily be interpreted by SuperCollider for the sound generation of the output melody (in the repository, along with the main Python code, you will also find the corresponding SuperCollider code).</p>

<p>In addition, the code can render graphs and images, such as the various heatmaps and the connected graph (via matplotlib and graphviz).</p>

<div style="text-align: center;">
<img loading="lazy" src="images/algorhythm_diagram.svg" width="1379.6713" height="942.80743" style="width: 80%; height: auto; margin-top: 2ch; margin-bottom: 2ch;"/></div>

<p>Thatâ€™s all for now. See you in the next experiment!</p>
<style type='text/css'>td.ref {  padding-bottom: 0ch; width:0;}</style><div class='heading' id='references'>References</div><hr/><p id='paperbox' style='text-align:left;'><table class='references'><tbody style='vertical-align: top;'><tr><td class='ref' style='width:1ch;'><a name="footnote_1"></a><a href="#back_1">^</a></td><td  class='ref' style='width:4ch;'> [1]</td><td style='width:100%;text-align:left;' class='ref'><a href="https://teropa.info/loop/#/title" target="_blank" rel="noopener noreferrer">wonderful introduction on generative music by Tero Parviainen</a></td></tr><tr><td class='ref' style='width:1ch;'><a name="footnote_2"></a><a href="#back_2">^</a></td><td  class='ref' style='width:4ch;'> [2]</td><td style='width:100%;text-align:left;' class='ref'><a href="https://en.wikipedia.org/wiki/Melody" target="_blank" rel="noopener noreferrer">Melody definition by WikiPedia</a></td></tr></tbody></table></p> <hr>
 <center>*